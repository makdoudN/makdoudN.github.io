{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate synthetic data\n",
    "def generate_data(n_samples, n_features, true_theta, true_thresholds, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for ordinal regression using a latent variable model.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples : int\n",
    "        Number of samples to generate.\n",
    "    n_features : int\n",
    "        Number of features.\n",
    "    true_theta : ndarray\n",
    "        True parameter vector for features.\n",
    "    true_thresholds : ndarray\n",
    "        True thresholds for ordinal categories.\n",
    "    sigma : float\n",
    "        Standard deviation of the latent variable.\n",
    "\n",
    "    Returns:\n",
    "    X : ndarray\n",
    "        Feature matrix.\n",
    "    y : ndarray\n",
    "        Ordinal target vector.\n",
    "    \"\"\"\n",
    "    X = np.random.randn(n_samples, n_features)  # Random feature matrix\n",
    "    z = X @ true_theta + np.random.normal(0, sigma, size=n_samples)  # Latent variable\n",
    "    thresholds = np.concatenate([[-np.inf], true_thresholds, [np.inf]])  # Include boundaries\n",
    "\n",
    "    # Determine y based on thresholds\n",
    "    y = np.digitize(z, thresholds) - 1  # Subtract 1 to make y start from 0\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_nll(X, y, theta, thresholds, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute the negative log-likelihood for ordinal regression (vectorized).\n",
    "\n",
    "    Parameters:\n",
    "    X : ndarray\n",
    "        Feature matrix where each row represents a sample and each column represents a feature.\n",
    "    y : ndarray\n",
    "        Target vector where each element is the target ordinal value for the corresponding sample.\n",
    "    theta : ndarray\n",
    "        Parameter vector for features (weights).\n",
    "    thresholds : ndarray\n",
    "        Thresholds for ordinal categories (K-1 cutpoints).\n",
    "    sigma : float\n",
    "        Standard deviation of the latent variable.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The negative log-likelihood value.\n",
    "    \"\"\"\n",
    "    # Compute the linear predictor\n",
    "    linear_pred = X @ theta  # shape: [n_samples]\n",
    "\n",
    "    # Prepend -inf and append +inf to thresholds for boundary conditions\n",
    "    thresholds = np.concatenate([[-np.inf], thresholds, [np.inf]])\n",
    "    \n",
    "    # Compute probabilities for each category (vectorized)\n",
    "    cdf_upper = norm.cdf((thresholds[y + 1] - linear_pred) / sigma)\n",
    "    cdf_lower = norm.cdf((thresholds[y] - linear_pred) / sigma)\n",
    "    prob_y = cdf_upper - cdf_lower\n",
    "\n",
    "    # Avoid log(0) with numerical stability\n",
    "    prob_y = np.clip(prob_y, 1e-15, 1 - 1e-15)\n",
    "    \n",
    "    # Compute negative log-likelihood\n",
    "    return -np.sum(np.log(prob_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters for synthetic data\n",
    "n_samples = 1000\n",
    "n_features = 3\n",
    "n_categories = 4  # K=4 ordinal categories\n",
    "true_theta = np.array([1.0, -1.0, 0.5])  # True feature weights\n",
    "true_thresholds = np.array([-1.0, 0.0, 1.0])  # True thresholds\n",
    "sigma_true = 1.0  # True sigma\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = generate_data(n_samples, n_features, true_theta, true_thresholds, sigma=sigma_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters for optimization\n",
    "theta_init = np.random.randn(n_features)  # Random initial weights\n",
    "thresholds_init = np.linspace(-2, 2, n_categories - 1)  # Evenly spaced initial thresholds\n",
    "params_init = np.concatenate([theta_init, thresholds_init])  # Combine parameters\n",
    "\n",
    "def unpack_params(params, n_features):\n",
    "    \"\"\"Helper function to unpack weights and thresholds.\"\"\"\n",
    "    theta = params[:n_features]\n",
    "    thresholds = params[n_features:]\n",
    "    return theta, thresholds\n",
    "\n",
    "# Wrapper for optimization function\n",
    "def nll_wrapper(params, X, y, sigma):\n",
    "    theta, thresholds = unpack_params(params, X.shape[1])\n",
    "    return ordinal_nll(X, y, theta, thresholds, sigma=sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Result:\n",
      "Success: True\n",
      "Message: Optimization terminated successfully.\n",
      "True Parameters (theta): [ 1.  -1.   0.5]\n",
      "Estimated Parameters (theta): [ 1.02232015 -1.03886499  0.48176276]\n",
      "True Thresholds: [-1.  0.  1.]\n",
      "Estimated Thresholds: [-1.00456218 -0.06331369  1.0246352 ]\n",
      "Function Value (Negative Log-Likelihood): 885.5286481795844\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optimize using scipy's minimize\n",
    "sigma_fixed = sigma_true  # Fix sigma to true value\n",
    "result = minimize(\n",
    "    lambda params: nll_wrapper(params, X, y, sigma_fixed),\n",
    "    params_init,\n",
    "    method='BFGS'\n",
    ")\n",
    "\n",
    "# Extract results\n",
    "theta_opt, thresholds_opt = unpack_params(result.x, n_features)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimization Result:\")\n",
    "print(\"Success:\", result.success)\n",
    "print(\"Message:\", result.message)\n",
    "print(\"True Parameters (theta):\", true_theta)\n",
    "print(\"Estimated Parameters (theta):\", theta_opt)\n",
    "print(\"True Thresholds:\", true_thresholds)\n",
    "print(\"Estimated Thresholds:\", thresholds_opt)\n",
    "print(\"Function Value (Negative Log-Likelihood):\", result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian model definition\n",
    "def ordinal_regression_model(X, y=None, n_categories=4):\n",
    "    \"\"\"\n",
    "    NumPyro model for Bayesian ordinal regression.\n",
    "\n",
    "    Parameters:\n",
    "    X : jnp.ndarray\n",
    "        Feature matrix.\n",
    "    y : jnp.ndarray or None\n",
    "        Ordinal target vector.\n",
    "    n_categories : int\n",
    "        Number of ordinal categories.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    # Priors for regression coefficients\n",
    "    beta = numpyro.sample(\"beta\", dist.Normal(jnp.zeros(n_features), 1.0))\n",
    "\n",
    "    # Priors for thresholds (sorted constraints are needed)\n",
    "    raw_thresholds = numpyro.sample(\"raw_thresholds\", dist.Normal(0.0, 1.0).expand([n_categories - 1]))\n",
    "    thresholds = jnp.sort(raw_thresholds)  # Ensure thresholds are ordered\n",
    "\n",
    "    # Prior for the standard deviation of the latent variable\n",
    "    sigma = numpyro.sample(\"sigma\", dist.Exponential(1.0))\n",
    "\n",
    "    # Linear predictor\n",
    "    linear_pred = jnp.dot(X, beta)\n",
    "\n",
    "    # Compute probabilities for each category\n",
    "    cdf_upper = dist.Normal(linear_pred, sigma).cdf(thresholds[y + 1])\n",
    "    cdf_lower = dist.Normal(linear_pred, sigma).cdf(thresholds[y])\n",
    "\n",
    "    # Clip CDF values to ensure numerical stability\n",
    "    cdf_upper = jnp.clip(cdf_upper, 0.0, 1.0)\n",
    "    cdf_lower = jnp.clip(cdf_lower, 0.0, 1.0)\n",
    "\n",
    "    prob_y = cdf_upper - cdf_lower\n",
    "\n",
    "    # Avoid invalid probabilities\n",
    "    prob_y = jnp.clip(prob_y, 1e-15, 1 - 1e-15)\n",
    "\n",
    "\n",
    "    # Likelihood\n",
    "    numpyro.sample(\"obs\", dist.Categorical(probs=prob_y), obs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 3000/3000 [00:18<00:00, 164.45it/s, 31 steps of size 2.77e-02. acc. prob=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                       mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "          beta[0]     -0.41      0.50     -0.39     -1.19      0.42    148.44      1.00\n",
      "          beta[1]      0.08      0.56      0.06     -0.74      1.07    199.24      1.00\n",
      "          beta[2]     -1.02      0.53     -0.99     -1.81     -0.15    176.92      1.00\n",
      "raw_thresholds[0]      0.32      0.50      0.31     -0.47      1.13    116.81      1.01\n",
      "raw_thresholds[1]     -1.33      0.64     -1.25     -2.46     -0.35    102.31      1.00\n",
      "raw_thresholds[2]      1.52      0.66      1.52      0.49      2.70    183.92      1.00\n",
      "            sigma      0.04      0.04      0.03      0.00      0.09    303.43      1.00\n",
      "\n",
      "Number of divergences: 900\n",
      "True Parameters:\n",
      "Theta: [ 1.  -1.   0.5]\n",
      "Thresholds: [-1.  0.  1.]\n",
      "Sigma: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Convert data to JAX arrays\n",
    "X = jnp.array(X)\n",
    "y = jnp.array(y)\n",
    "\n",
    "# Run MCMC\n",
    "rng_key = random.PRNGKey(0)\n",
    "nuts_kernel = NUTS(ordinal_regression_model)\n",
    "mcmc = MCMC(nuts_kernel, num_warmup=1000, num_samples=2000, num_chains=1)\n",
    "mcmc.run(rng_key, X=X, y=y, n_categories=n_categories)\n",
    "mcmc.print_summary()\n",
    "\n",
    "# Extract posterior samples\n",
    "posterior_samples = mcmc.get_samples()\n",
    "\n",
    "# Print results\n",
    "print(\"True Parameters:\")\n",
    "print(f\"Theta: {true_theta}\")\n",
    "print(f\"Thresholds: {true_thresholds}\")\n",
    "print(f\"Sigma: {sigma_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
