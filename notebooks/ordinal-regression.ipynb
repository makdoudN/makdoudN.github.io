{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate synthetic data\n",
    "def generate_data(n_samples, n_features, true_theta, true_thresholds, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for ordinal regression using a latent variable model.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples : int\n",
    "        Number of samples to generate.\n",
    "    n_features : int\n",
    "        Number of features.\n",
    "    true_theta : ndarray\n",
    "        True parameter vector for features.\n",
    "    true_thresholds : ndarray\n",
    "        True thresholds for ordinal categories.\n",
    "    sigma : float\n",
    "        Standard deviation of the latent variable.\n",
    "\n",
    "    Returns:\n",
    "    X : ndarray\n",
    "        Feature matrix.\n",
    "    y : ndarray\n",
    "        Ordinal target vector.\n",
    "    \"\"\"\n",
    "    X = np.random.randn(n_samples, n_features)  # Random feature matrix\n",
    "    z = X @ true_theta + np.random.normal(0, sigma, size=n_samples)  # Latent variable\n",
    "    thresholds = np.concatenate([[-np.inf], true_thresholds, [np.inf]])  # Include boundaries\n",
    "\n",
    "    # Determine y based on thresholds\n",
    "    y = np.digitize(z, thresholds) - 1  # Subtract 1 to make y start from 0\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters for synthetic data\n",
    "n_samples = 1000\n",
    "n_features = 3\n",
    "n_categories = 4  # K=4 ordinal categories\n",
    "true_theta = np.array([1.0, -1.0, 0.5])  # True feature weights\n",
    "true_thresholds = np.array([-5.0, 0.35, 1.0])  # True thresholds\n",
    "sigma_true = 1.0  # True sigma\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = generate_data(n_samples, n_features, true_theta, true_thresholds, sigma=sigma_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.91929931, -0.69315003,  0.38316362],\n",
       "       [-0.19971782, -0.74760958,  1.30834944],\n",
       "       [-0.05138498, -0.35874265, -0.4470689 ],\n",
       "       ...,\n",
       "       [ 0.9987484 , -1.62450618,  0.52863981],\n",
       "       [ 1.94642874, -1.33544859, -0.05489007],\n",
       "       [-0.63756448, -2.62269038, -0.7387322 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 3, 3, 1,\n",
       "       1, 2, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 1, 3, 1, 3, 1, 1,\n",
       "       1, 3, 1, 1, 1, 3, 3, 1, 1, 3, 1, 1, 3, 3, 3, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 3, 3, 2, 3, 1, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 3, 1, 1, 2, 2, 3, 1, 3, 1, 1, 3, 1, 2, 1, 1, 1, 3,\n",
       "       2, 3, 3, 2, 3, 3, 2, 3, 1, 1, 1, 0, 3, 2, 2, 1, 1, 3, 1, 2, 3, 2,\n",
       "       1, 1, 1, 1, 1, 3, 3, 2, 1, 1, 1, 3, 3, 1, 3, 2, 2, 1, 3, 1, 1, 3,\n",
       "       3, 2, 1, 3, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 3, 3, 3, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 3, 1, 2, 3, 1, 2, 3, 3, 1, 3, 3, 1, 1, 1, 2, 1,\n",
       "       3, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 3, 2, 1, 1, 1, 1, 2, 2, 3, 1,\n",
       "       1, 1, 3, 3, 1, 1, 3, 1, 1, 1, 3, 1, 3, 1, 1, 1, 3, 3, 2, 1, 3, 1,\n",
       "       3, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 3,\n",
       "       1, 1, 1, 3, 2, 1, 1, 3, 3, 1, 3, 1, 2, 2, 1, 1, 1, 1, 3, 1, 3, 3,\n",
       "       1, 2, 3, 2, 1, 1, 1, 2, 3, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 3, 3,\n",
       "       1, 1, 3, 1, 1, 3, 3, 1, 1, 3, 3, 3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 3,\n",
       "       1, 1, 3, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 3, 3, 1, 1,\n",
       "       3, 3, 1, 1, 1, 2, 3, 1, 1, 3, 3, 1, 2, 1, 3, 1, 2, 1, 2, 3, 3, 1,\n",
       "       3, 3, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1,\n",
       "       1, 1, 1, 3, 1, 2, 3, 2, 1, 2, 1, 1, 1, 1, 3, 2, 3, 1, 1, 1, 3, 1,\n",
       "       1, 1, 3, 1, 1, 3, 1, 3, 1, 1, 1, 2, 2, 1, 1, 3, 3, 1, 1, 3, 1, 3,\n",
       "       1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 1, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1,\n",
       "       3, 1, 1, 3, 3, 1, 3, 1, 3, 3, 1, 3, 1, 1, 1, 3, 1, 1, 3, 1, 1, 3,\n",
       "       1, 1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1,\n",
       "       1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1,\n",
       "       1, 3, 1, 1, 3, 1, 3, 1, 3, 2, 1, 1, 3, 2, 1, 2, 1, 1, 1, 3, 1, 1,\n",
       "       1, 3, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2,\n",
       "       3, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 3, 3, 3, 1, 2, 1, 1,\n",
       "       3, 3, 3, 3, 1, 1, 2, 3, 1, 2, 2, 1, 3, 1, 1, 3, 1, 2, 1, 3, 1, 3,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 3, 3, 2, 3, 1, 1, 1, 1, 3, 1,\n",
       "       3, 1, 1, 1, 3, 2, 1, 2, 3, 1, 1, 3, 1, 1, 1, 3, 3, 1, 3, 1, 2, 1,\n",
       "       3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 2, 3, 1,\n",
       "       3, 1, 1, 2, 3, 3, 1, 1, 3, 1, 3, 2, 3, 1, 3, 1, 3, 2, 1, 1, 1, 3,\n",
       "       3, 2, 3, 2, 1, 1, 3, 1, 2, 2, 1, 1, 3, 3, 2, 1, 1, 2, 1, 3, 3, 2,\n",
       "       3, 3, 2, 1, 1, 1, 1, 2, 1, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1,\n",
       "       1, 2, 1, 1, 3, 1, 1, 3, 2, 1, 3, 1, 1, 3, 1, 1, 3, 2, 3, 1, 1, 1,\n",
       "       1, 1, 1, 3, 1, 2, 1, 0, 1, 3, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 3, 3,\n",
       "       1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 3, 3, 1, 3, 1, 1, 1, 3, 1, 1, 2, 3,\n",
       "       3, 1, 3, 1, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 3, 1, 3,\n",
       "       3, 3, 3, 1, 1, 3, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1,\n",
       "       1, 3, 3, 1, 1, 3, 2, 1, 1, 1, 1, 3, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 2, 3, 1, 1, 3, 1, 3, 1, 1, 3, 1, 2, 1, 2, 1, 3, 3, 1, 3, 1, 1,\n",
       "       3, 2, 1, 3, 3, 1, 1, 3, 3, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 2, 1, 1,\n",
       "       3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 3, 3, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 3, 1, 1, 1, 3, 3, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 3,\n",
       "       1, 2, 3, 1, 3, 1, 1, 3, 3, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_nll(X, y, theta, thresholds, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute the negative log-likelihood for ordinal regression (vectorized).\n",
    "\n",
    "    Parameters:\n",
    "    X : ndarray\n",
    "        Feature matrix where each row represents a sample and each column represents a feature.\n",
    "    y : ndarray\n",
    "        Target vector where each element is the target ordinal value for the corresponding sample.\n",
    "    theta : ndarray\n",
    "        Parameter vector for features (weights).\n",
    "    thresholds : ndarray\n",
    "        Thresholds for ordinal categories (K-1 cutpoints).\n",
    "    sigma : float\n",
    "        Standard deviation of the latent variable.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The negative log-likelihood value.\n",
    "    \"\"\"\n",
    "    # Compute the linear predictor\n",
    "    linear_pred = X @ theta  # shape: [n_samples]\n",
    "\n",
    "    # Prepend -inf and append +inf to thresholds for boundary conditions\n",
    "    thresholds = np.concatenate([[-np.inf], thresholds, [np.inf]])\n",
    "    \n",
    "    # Compute probabilities for each category (vectorized)\n",
    "    cdf_upper = norm.cdf((thresholds[y + 1] - linear_pred) / sigma)\n",
    "    cdf_lower = norm.cdf((thresholds[y] - linear_pred) / sigma)\n",
    "    prob_y = cdf_upper - cdf_lower\n",
    "\n",
    "    # Avoid log(0) with numerical stability\n",
    "    prob_y = np.clip(prob_y, 1e-15, 1 - 1e-15)\n",
    "    \n",
    "    # Compute negative log-likelihood\n",
    "    return -np.sum(np.log(prob_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unpack_params(params, n_features):\n",
    "    \"\"\"Helper function to unpack weights and thresholds.\"\"\"\n",
    "    theta = params[:n_features]\n",
    "    thresholds = params[n_features:]\n",
    "    return theta, thresholds\n",
    "\n",
    "# Wrapper for optimization function\n",
    "def nll_wrapper(params, X, y, sigma):\n",
    "    theta, thresholds = unpack_params(params, X.shape[1])\n",
    "    return ordinal_nll(X, y, theta, thresholds, sigma=sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Result:\n",
      "Success: True\n",
      "Message: Optimization terminated successfully.\n",
      "True Parameters (theta): [ 1.  -1.   0.5]\n",
      "Estimated Parameters (theta): [ 0.37310853  1.0823132  -0.51291999]\n",
      "True Thresholds: [-5.    0.35  1.  ]\n",
      "Estimated Thresholds: [-5.  0.  5.]\n",
      "Function Value (Negative Log-Likelihood): 8662.076\n"
     ]
    }
   ],
   "source": [
    "# Initial parameters for optimization\n",
    "theta_init = np.random.randn(n_features)  # Random initial weights\n",
    "thresholds_init = np.linspace(-5, 5, n_categories - 1)  # Evenly spaced initial thresholds\n",
    "params_init = np.concatenate([theta_init, thresholds_init])  # Combine parameters\n",
    "\n",
    "# Optimize using scipy's minimize\n",
    "sigma_fixed = sigma_true  # Fix sigma to true value\n",
    "result = minimize(\n",
    "    lambda params: nll_wrapper(params, X, y, sigma_fixed),\n",
    "    params_init,\n",
    "    method='BFGS'\n",
    ")\n",
    "\n",
    "# Extract results\n",
    "theta_opt, thresholds_opt = unpack_params(result.x, n_features)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimization Result:\")\n",
    "print(\"Success:\", result.success)\n",
    "print(\"Message:\", result.message)\n",
    "print(\"True Parameters (theta):\", true_theta)\n",
    "print(\"Estimated Parameters (theta):\", theta_opt)\n",
    "print(\"True Thresholds:\", true_thresholds)\n",
    "print(\"Estimated Thresholds:\", thresholds_opt)\n",
    "print(\"Function Value (Negative Log-Likelihood):\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `m01` Ordinal Bayesian Modeling with Fixed Cutpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_thresholds = np.array([-1.0, 0, 1])  # Fixed cutpoints\n",
    "\n",
    "def ordinal_probit_model(X, y, alpha_cutpoints, sigma_beta=2.0, sigma_z=1.0):\n",
    "    \"\"\"\n",
    "    Bayesian Ordinal Probit Model with fixed cutpoints and latent variables.\n",
    "    For identification, we fix sigma_z=1.0 (standard probit model assumption).\n",
    "    \n",
    "    Args:\n",
    "        X (array): Input features of shape (n_samples, n_features)\n",
    "        y (array): Target ordinal labels of shape (n_samples,)\n",
    "        alpha_cutpoints (array-like): Fixed cutoff points for ordinal categories\n",
    "        sigma_beta (float): Standard deviation for beta prior\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    n_samples, num_features = X.shape\n",
    "    num_categories = len(alpha_cutpoints) + 1\n",
    "        \n",
    "    # Sample regression coefficients from prior with larger variance\n",
    "    beta = numpyro.sample(\n",
    "        \"beta\",\n",
    "        dist.Normal(\n",
    "            loc=jnp.zeros(num_features),\n",
    "            scale=jnp.ones(num_features) * sigma_beta\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    z = jnp.dot(X, beta)\n",
    "    \n",
    "    # Compute probabilities using the standard normal CDF\n",
    "    probs = jnp.zeros((n_samples, num_categories))\n",
    "    \n",
    "    # Binary classification case\n",
    "    # P(y=1) = P(z ≤ α)\n",
    "    p1 = numpyro.distributions.Normal(0, 1).cdf((alpha_cutpoints[0] - z))\n",
    "    probs = probs.at[:, 0].set(p1)\n",
    "    probs = probs.at[:, 1].set(1 - p1)\n",
    "\n",
    "    # Ensure probabilities sum to 1 and are positive\n",
    "    probs = jnp.clip(probs, 1e-8, 1.0)\n",
    "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Sample observations\n",
    "    with numpyro.plate(\"obs\", n_samples):\n",
    "        numpyro.sample(\"y\", dist.Categorical(probs=probs), obs=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 3500/3500 [00:01<00:00, 1851.99it/s, 5 steps of size 7.80e-01. acc. prob=0.91] \n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(ordinal_probit_model)\n",
    "mcmc = MCMC(nuts_kernel, num_warmup=1500, num_samples=2000, num_chains=1)\n",
    "mcmc.run(jax.random.PRNGKey(0), X=X, y=y, alpha_cutpoints=fixed_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "   beta[0]     -0.46      0.09     -0.47     -0.61     -0.31   1733.17      1.00\n",
      "   beta[1]      0.48      0.09      0.48      0.33      0.63   1561.80      1.00\n",
      "   beta[2]     -0.20      0.08     -0.20     -0.33     -0.08   1594.31      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/y7css5mj58d0d43d5rmmv58m0000gp/T/ipykernel_75333/3497928026.py:87: UserWarning: There are not enough devices to run parallel chains: expected 4 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(4)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  mcmc = MCMC(kernel, num_warmup=1000, num_samples=2000, num_chains=4)\n",
      "sample: 100%|██████████| 3000/3000 [00:26<00:00, 113.66it/s, 59 steps of size 4.08e-02. acc. prob=0.97] \n",
      "sample: 100%|██████████| 3000/3000 [00:07<00:00, 403.89it/s, 6 steps of size 1.74e-01. acc. prob=0.91] \n",
      "sample: 100%|██████████| 3000/3000 [00:05<00:00, 534.09it/s, 12 steps of size 2.70e-01. acc. prob=0.88]\n",
      "sample: 100%|██████████| 3000/3000 [00:05<00:00, 524.85it/s, 3 steps of size 3.02e-01. acc. prob=0.85] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>3111.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1]</th>\n",
       "      <td>-1.004</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-1.094</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>2431.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2]</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3561.0</td>\n",
       "      <td>3996.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_points[0]</th>\n",
       "      <td>-4.519</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-4.975</td>\n",
       "      <td>-4.039</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_points[1]</th>\n",
       "      <td>0.372</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2744.0</td>\n",
       "      <td>2692.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_points[2]</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>3408.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "beta[0]        0.938  0.047   0.847    1.020      0.001    0.001    2127.0   \n",
       "beta[1]       -1.004  0.048  -1.094   -0.913      0.001    0.001    2132.0   \n",
       "beta[2]        0.441  0.047   0.354    0.528      0.001    0.001    3561.0   \n",
       "cut_points[0] -4.519  0.254  -4.975   -4.039      0.005    0.004    2435.0   \n",
       "cut_points[1]  0.372  0.052   0.279    0.472      0.001    0.001    2744.0   \n",
       "cut_points[2]  0.950  0.053   0.849    1.051      0.001    0.001    3015.0   \n",
       "\n",
       "               ess_tail  r_hat  \n",
       "beta[0]          3111.0    1.0  \n",
       "beta[1]          2431.0    1.0  \n",
       "beta[2]          3996.0    1.0  \n",
       "cut_points[0]    2185.0    1.0  \n",
       "cut_points[1]    2692.0    1.0  \n",
       "cut_points[2]    3408.0    1.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.stats import norm\n",
    "from numpyro.distributions import constraints, CategoricalProbs\n",
    "from numpyro.distributions.util import promote_shapes\n",
    "\n",
    "class OrderedProbit(CategoricalProbs):\n",
    "    \"\"\"\n",
    "    A categorical distribution with ordered outcomes, using a Probit link.\n",
    "\n",
    "    :param numpy.ndarray predictor: predictions in the real domain; typically the output\n",
    "        of a linear model.\n",
    "    :param numpy.ndarray cutpoints: positions in the real domain to separate categories.\n",
    "    \"\"\"\n",
    "\n",
    "    arg_constraints = {\n",
    "        \"predictor\": constraints.real,\n",
    "        \"cutpoints\": constraints.ordered_vector,\n",
    "    }\n",
    "\n",
    "    def __init__(self, predictor, cutpoints, *, validate_args=None):\n",
    "        if jnp.ndim(predictor) == 0:\n",
    "            (predictor,) = promote_shapes(predictor, shape=(1,))\n",
    "        else:\n",
    "            predictor = predictor[..., None]\n",
    "        predictor, cutpoints = promote_shapes(predictor, cutpoints)\n",
    "        self.predictor = predictor[..., 0]\n",
    "        self.cutpoints = cutpoints\n",
    "\n",
    "        # Compute cumulative probabilities using the probit link (normal CDF)\n",
    "        cdf = norm.cdf\n",
    "        probs = jnp.concatenate([\n",
    "            cdf(self.cutpoints[..., 0] - self.predictor[..., None]),\n",
    "            cdf(self.cutpoints[..., 1:] - self.predictor[..., None]) -\n",
    "            cdf(self.cutpoints[..., :-1] - self.predictor[..., None]),\n",
    "            1.0 - cdf(self.cutpoints[..., -1] - self.predictor[..., None])\n",
    "        ], axis=-1)\n",
    "\n",
    "        super(OrderedProbit, self).__init__(probs, validate_args=validate_args)\n",
    "\n",
    "    @staticmethod\n",
    "    def infer_shapes(predictor, cutpoints):\n",
    "        batch_shape = jnp.broadcast_shapes(predictor.shape, cutpoints[:-1].shape)\n",
    "        event_shape = ()\n",
    "        return batch_shape, event_shape\n",
    "\n",
    "    def entropy(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "# Step 1: Define the model in NumPyro\n",
    "def ordinal_regression_model(X, y=None, n_categories=4):\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # Priors for regression coefficients\n",
    "    beta = numpyro.sample(\"beta\", dist.Normal(jnp.zeros(n_features), jnp.ones(n_features)))\n",
    "    \n",
    "    # Dirichlet prior for category probabilities\n",
    "    alpha = jnp.ones(n_categories)\n",
    "    p = numpyro.sample(\"p\", dist.Dirichlet(alpha))\n",
    "    \n",
    "    # Cumulative probabilities derived from p\n",
    "    q = jnp.cumsum(p[:-1])\n",
    "    \n",
    "    # Cut points derived using probit link (inverse CDF of normal distribution)\n",
    "    cut_points = numpyro.deterministic(\"cut_points\", dist.Normal(0, 1).icdf(q))\n",
    "    \n",
    "    # Linear predictor for latent variable z\n",
    "    z = jnp.dot(X, beta)\n",
    "    \n",
    "\n",
    "    # Observational model\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"y\", OrderedProbit(predictor=z, cutpoints=cut_points), obs=y)\n",
    "\n",
    "        \n",
    "# Step 2: Generate synthetic data\n",
    "cut_points_true = true_thresholds\n",
    "# Step 3: Run MCMC with NumPyro\n",
    "rng_key = random.PRNGKey(0)\n",
    "kernel = NUTS(ordinal_regression_model)\n",
    "mcmc = MCMC(kernel, num_warmup=1000, num_samples=2000, num_chains=4)\n",
    "mcmc.run(rng_key, X=jnp.array(X), y=jnp.array(y), n_categories=4)\n",
    "\n",
    "# Step 4: Extract results\n",
    "posterior_samples = mcmc.get_samples()\n",
    "\n",
    "# Display posterior summaries\n",
    "import arviz as az\n",
    "idata = az.from_numpyro(mcmc)\n",
    "az.summary(idata, var_names=[\"beta\", \"cut_points\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_points_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
